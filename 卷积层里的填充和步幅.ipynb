{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ff47ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 填充\n",
    "# 给定(32x32)输入图像\n",
    "# 应用5x5大小的卷积核\n",
    "#   - 第1层得到输出大小28x28\n",
    "#   - 第7层得到输出大小4x4\n",
    "# 更大的卷积核可以更快地减小输出大小\n",
    "#   - 形状从n_h x n_w 减少到\n",
    "#   - (n_h - k_h +1) x (n_w - k_w +1)\n",
    "\n",
    "# 填充 (padding)\n",
    "# 在输入周围添加额外的行/列\n",
    "# 填充(p_h)行和(p_w)列, 输出形状为 (n_h - k_h + p_h -1) x (n_w - k_w + p_w -1)\n",
    "# 通常取 p_h = k_h -1, p_w = k_w -1\n",
    "# 因为这样, 将p_h和p_w带入后, 可以发现 输出形状变为 (n_h) x (n_w), 也就是\"不会改变输出的形状\"\n",
    "#   - 当 k_h 为奇数: 在上下两侧填充 p_h/2\n",
    "#   - 当 k_h 为偶数, 在上侧填充ceiling(p_h/2), floor(p_h/2) --> 我们基本不会用偶数卷积核\n",
    "\n",
    "# 步幅 (stride)\n",
    "# 填充减小的输出大小与线性层相关\n",
    "#   - 给定输入大小224x224, 在使用5x5卷积核的情况下, 需要44层将输出降低为4x4\n",
    "#   - 需要大量计算才能得到较小的输出\n",
    "# 步幅是指行/列的滑动步长\n",
    "# 例: 高度3 宽度2 的步幅\n",
    "# 当没得跳一个完全的步幅时, 停止\n",
    "\n",
    "# 步幅\n",
    "# 给定高度s_h和宽度s_w的步幅, 输出的形状是 \n",
    "#    - floor((n_h - k_h + p_h + s_h)/s_h) x floor((n_w - k_w + p_w + s_w)/s_w)\n",
    "#    - 为什么这里是 + s_h/w? 可以理解为我们先减去 k占据的部分, 如果末尾部分不满足stride, 就用floor将他取0\n",
    "# 如果p_h = k_h -1, p_w = k_w -1\n",
    "#    - floor((n_h + s_h -1)/s_h) x floor((n_w + s_w -1)/s_w)\n",
    "# 如果输入的高度, 宽度都可以被步幅整除\n",
    "#    - （n_h/s_h) x (n_w/s_w)\n",
    "\n",
    "# 总结\n",
    "# 填充和步幅是卷积层的超参数\n",
    "# 填充在输入周围添加额外的行/列, 来控制输出的形状的减少量\n",
    "# 步幅是每次滑动核窗口时的行/列的步长, 可以成倍的减少输出形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "712f6f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 填充和步幅\n",
    "# 在所有侧边填充1个像素\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "def comp_conv2d(conv2d, X):\n",
    "    X = X.reshape((1, 1) + X.shape) # (1,1)是通道数和批量大小数; X.shape是维度\n",
    "    Y = conv2d(X)\n",
    "    return Y.reshape(Y.shape[2:]) # 输出是个4维的矩阵, 将前2维拿掉\n",
    "\n",
    "conv2d = nn.Conv2d(1, 1, kernel_size=3, padding=1) #输入的通道数和批量大小都是1, Kernel大小为3x3, padding为1\n",
    "X = torch.rand(size= (8,8)) # 生成一个随机的8x8的矩阵\n",
    "comp_conv2d(conv2d, X).shape # 输出是一个8x8, 因为 (8+2(padding *2) +1 -3) = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06420ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 填充不同的高度和宽度\n",
    "conv2d = nn.Conv2d(1, 1, kernel_size=(5,3), padding=(2,1)) # 上下填充的行数是2, 左右填充的列数是1\n",
    "# height = 8 - 5 + 2*2 + 1 = 8\n",
    "# width = 8 - 3 + 1*2 +1 = 8\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3de066e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将高度和宽度的步幅设置为2\n",
    "conv2d = nn.Conv2d(1, 1, kernel_size=3, padding=1, stride=2)\n",
    "# (8-3+1*2+1)/2 = 4 \n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1987af6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 一个稍微复杂的例子\n",
    "conv2d = nn.Conv2d(1, 1, kernel_size=(3,5), padding=(0,1), stride=(3,4))\n",
    "# floor((8-3+0*2)/4+1) = 2\n",
    "# floor((8-5+1*2)/3+1) = 2\n",
    "# 注意这里除数是要换\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dae3a81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
